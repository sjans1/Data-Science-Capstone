{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Data Science Capstone project on NYC Traffic Flow\n\nThere is a wealth of publicly available data on NYC available on data.cityofnewyork.us - I am enriching the Foursquare provided information with this dataset on New York City Traffic flow.\n\nThere are two phases to the deliverable. Initially I want to be able to:\n- (1) Visualise spatial and traffic and Foursquare data by plotting (a) Venues, (b) Traffic speeds, and (c) the map of New York city to have an overvie of the business that are easily accessible by car.\n- (2) Apply filters to plot traffic data over different days and time periods.\n\nIn the second phase I intend to perform an analysis on the traffic data to better understand\n- (3) what kind of businesses are located near places that have good or fast traffic throughput and \n- (4) to identify what the kinds of businesses are that have poor traffic throughput nearby.\n\n## Business Problem\nThe business problem is that the NYC government wants to better understand what areas have good or poor traffic flow in combination with the different venues in that location. They want to better understand what areas suffer from poor traffic flow to see which areas and which venues in what areas cannot be accessed easily by car.\nTarget audience: NYC government.\n\n## Data Required\n- Foursquare: Foursquare API can be used to gather information about venues near a certain location. It also contains latitudes and longitudes.\n- Folium is used to plot maps\n- Traffic data contains speed, latitude, longitude and a number of other variables that can be used to determine the traffic throughput in that road/area.\n\n### Data links\n- Foursquare API: https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}\n- Traffic Data (1): The traffic data from October 2016 https://www.kaggle.com/crailtap/nyc-real-time-traffic-speed-data-feed#october2016.csv\n- Traffic Data (2): The node information for the traffic data referred to in the October 2016 dataset: https://www.kaggle.com/crailtap/nyc-real-time-traffic-speed-data-feed#linkinfo.csv\n\nThe traffic file (1) contains the following columns:\n- Id\n- Speed\n- TravelTime\n- Status\n- DataAsOf\n- linkId\n\nTraffic Data file (2) contains these columns:\n- linkId\n- linkPoints\n- EncodedPolyLine\n- EncodedPolyLineLvls\n- Transcom_id\n- Borough\n- linkName\n- Owner\n\nThe Foursquare API calls will return at least the following information which I will use:\n- Venue Latitude\n- Venue Longitude\n- Venue Category\n- Venue Name\n\nTraffic Data (1) provides the information about the traffic speed on road segments identified by ID\nTraffic Data (2) provides the information about the locations of road segments and is also identified by ID\nFoursquare data contains the Venue Category and the location (coordinates) of the venues.\n\nTogether they can be used to visualize all this data together and perform analysis on the above listed features.\n\n\n## Aproach\n\n### 1 Visualise spatial and traffic and Foursquare data by plotting (a) Venues, (b) Traffic speeds, and (c) the map of New York city.\n- Use Folium to plot the map,\n- Use Traffic Data File (1) to Determine traffic speed and the street ID\n- Use Traffic Data File (2) to identify the latitude and longitude of the street ID\n- Use Foursquare API to identify Venues near the Street location\n\n### 2 Apply filters to plot traffic data over different days and time periods.\n- Investigate how to make the map interactive to visualize the changes in traffic speeds over different days and time periods in the month of October 2016\n- Classify areas and their traffic speeds taking into account the timeseries data where traffic speeds differ over time\n\n### 3 What kind of businesses are located near places that have good or fast traffic throughput.\n### 4 Identify what the kinds of businesses are that have poor traffic throughput nearby.\n- Build a dataset of Venues and their locations (Latitude and Longitudes) using the Foursquare API, store all this information in a Dataframe in Watson Studio so we can refer to it without querying the Foursquare API.\n- Try out various machine learning algorithms (exploratory) to look into correlations between Venue Category and Traffic speeds in NYC.\n- Cluster business categories based on the locations and the traffic speeds nearby those locations\n\n\n\n"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Solving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/Python36\n\n  added / updated specs: \n    - folium=0.5.0\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    branca-0.3.1               |             py_0          25 KB  conda-forge\n    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n    vincent-0.4.4              |             py_1          28 KB  conda-forge\n    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n    folium-0.5.0               |             py_0          45 KB  conda-forge\n    certifi-2019.11.28         |           py36_0         149 KB  conda-forge\n    altair-4.0.1               |             py_0         575 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         3.0 MB\n\nThe following NEW packages will be INSTALLED:\n\n    altair:          4.0.1-py_0        conda-forge\n    branca:          0.3.1-py_0        conda-forge\n    folium:          0.5.0-py_0        conda-forge\n    vincent:         0.4.4-py_1        conda-forge\n\nThe following packages will be UPDATED:\n\n    ca-certificates: 2019.11.27-0                  --> 2019.11.28-hecc5488_0 conda-forge\n    certifi:         2019.11.28-py36_0             --> 2019.11.28-py36_0     conda-forge\n\nThe following packages will be DOWNGRADED:\n\n    openssl:         1.1.1d-h7b6447c_3             --> 1.1.1d-h516909a_0     conda-forge\n\n\nDownloading and Extracting Packages\nbranca-0.3.1         | 25 KB     | ##################################### | 100% \nca-certificates-2019 | 145 KB    | ##################################### | 100% \nvincent-0.4.4        | 28 KB     | ##################################### | 100% \nopenssl-1.1.1d       | 2.1 MB    | ##################################### | 100% \nfolium-0.5.0         | 45 KB     | ##################################### | 100% \ncertifi-2019.11.28   | 149 KB    | ##################################### | 100% \naltair-4.0.1         | 575 KB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n"
                }
            ],
            "source": "import requests # library to handle requests\nimport pandas as pd # library for data analsysis\nimport numpy as np # library to handle data in a vectorized manner\nimport random # library for random number generation\nimport datetime # For timeseries\n\n#!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n    \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\n!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # plotting library"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Start with setting the variables for the Foursquare API and determining the NYC location, as well as creating the main function for quering Venues in a location"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "CLIENT_ID = 'VSKNDXQXCA0IPVQ4AMSF40AGK4AUAIVWI41XKCLMO4X1EAG2' # your Foursquare ID\n# Client secret is in hidden cell below\nVERSION = '20180604'\nLIMIT = 30"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "40.7149555 -74.0153365\n"
                }
            ],
            "source": "address = '102 North End Ave, New York, NY'\n\ngeolocator = Nominatim(user_agent=\"foursquare_agent\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint(latitude, longitude)"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for lat, lng in zip(latitudes, longitudes):\n                    \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        #return only relevant information for each nearby venue\n        venues_list.append([(\n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": "nyc = getNearbyVenues(\n                                   latitudes=[40.7127281],\n                                   longitudes=[-74.0060152]\n                                  )"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The coordinates of NYC are 40.7127281, -74.0060152.\n"
                }
            ],
            "source": "place ='New York City,United States'\n\ngeolocator=Nominatim(user_agent='can_explorer')\nlocation = geolocator.geocode(place)\nlatitude=location.latitude\nlongitude=location.longitude\nprint('The coordinates of NYC are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Create the Traffic Dataset that contains the locations of the segments and store it in a Pandas DataFrame - df_linkinfo"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": "df_linkinfo = pd.read_csv(body)"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>linkId</th>\n      <th>linkPoints</th>\n      <th>EncodedPolyLineLvls</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4616337</td>\n      <td>40.74047,-74.009251 40.74137,-74.00893 40.7431...</td>\n      <td>BBBBBBBBBBBBB</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4616325</td>\n      <td>40.73933,-74.01004 40.73895,-74.01012 40.7376,...</td>\n      <td>BBBBBB</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4616324</td>\n      <td>40.76375,-73.999191 40.763521,-73.99935 40.762...</td>\n      <td>BBBBBBBBBBBBBBB</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4616338</td>\n      <td>40.7607,-74.002141 40.76212,-74.91 40.76335,-7...</td>\n      <td>BBBBBBBBB</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4616323</td>\n      <td>40.77158,-73.994441 40.7713004,-73.99455 40.77...</td>\n      <td>BBBBBBBBBBBBBBBBB</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "    linkId                                         linkPoints  \\\n0  4616337  40.74047,-74.009251 40.74137,-74.00893 40.7431...   \n1  4616325  40.73933,-74.01004 40.73895,-74.01012 40.7376,...   \n2  4616324  40.76375,-73.999191 40.763521,-73.99935 40.762...   \n3  4616338  40.7607,-74.002141 40.76212,-74.91 40.76335,-7...   \n4  4616323  40.77158,-73.994441 40.7713004,-73.99455 40.77...   \n\n  EncodedPolyLineLvls  \n0       BBBBBBBBBBBBB  \n1              BBBBBB  \n2     BBBBBBBBBBBBBBB  \n3           BBBBBBBBB  \n4   BBBBBBBBBBBBBBBBB  "
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_linkinfo.drop([\"EncodedPolyLine\", \"Transcom_id\", \"Borough\", \"linkName\", \"Owner\"], axis=1, inplace=True)\ndf_linkinfo.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": "#df_linkinfo['EncodedPolyLineLvls'] = df_linkinfo['EncodedPolyLineLvls'].apply(lambda x: (min(12,len(str(x)))))\ndf_linkinfo['EncodedPolyLineLvls'] = df_linkinfo['EncodedPolyLineLvls'].apply(lambda x: (len(str(x))))"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "ename": "SyntaxError",
                    "evalue": "invalid syntax (<ipython-input-20-ace90239a083>, line 1)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-ace90239a083>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df_linkinfo = pd.concat([df_linkinfo, tuple(map(float, df_linkinfo.linkPoints.str.split(expand=True)], axis=1, sort=False).split(','))\u001b[0m\n\u001b[0m                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
                    ]
                }
            ],
            "source": "df_linkinfo = pd.concat([df_linkinfo, tuple(map(float, df_linkinfo.linkPoints.str.split(expand=True)], axis=1, sort=False).split(','))"
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [],
            "source": "#Because the data is incomplete in the csv for all segments after segment (lat/longitude coordinates) 12\ndf_linkinfo.drop(df_linkinfo.columns[len(df_linkinfo.columns)-1], axis=1, inplace=True)\ndf_linkinfo.drop(\"linkPoints\", inplace=True, axis=1)\ndf_linkinfo.rename(columns={0: 'point0', 1: 'point1', 2: 'point2', 3: 'point3', 4: 'point4', 5: 'point5', 6: 'point6', 7: 'point7', 8: 'point8',9: 'point9', 10: 'point10', 11: 'point11', 12: 'point12'}, inplace=True)"
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>linkId</th>\n      <th>EncodedPolyLineLvls</th>\n      <th>point0</th>\n      <th>point1</th>\n      <th>point2</th>\n      <th>point3</th>\n      <th>point4</th>\n      <th>point5</th>\n      <th>point6</th>\n      <th>point7</th>\n      <th>point8</th>\n      <th>point9</th>\n      <th>point10</th>\n      <th>point11</th>\n      <th>point12</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4616337</td>\n      <td>13</td>\n      <td>40.74047,-74.009251</td>\n      <td>40.74137,-74.00893</td>\n      <td>40.7431706,-74.008591</td>\n      <td>40.7462304,-74.00797</td>\n      <td>40.74812,-74.007651</td>\n      <td>40.748701,-74.007691</td>\n      <td>40.74971,-74.00819</td>\n      <td>40.75048,-74.008321</td>\n      <td>40.751611,-74.00789</td>\n      <td>40.7537504,-74.00704</td>\n      <td>40.75721,-74.00463</td>\n      <td>40.76003,-74.002631</td>\n      <td>40.7607405,-7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4616325</td>\n      <td>6</td>\n      <td>40.73933,-74.01004</td>\n      <td>40.73895,-74.01012</td>\n      <td>40.7376,-74.010021</td>\n      <td>40.7346,-74.01026</td>\n      <td>40.72912,-74.010781</td>\n      <td>40.72619,-74.011131</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4616324</td>\n      <td>15</td>\n      <td>40.76375,-73.999191</td>\n      <td>40.763521,-73.99935</td>\n      <td>40.7620804,-74.00136</td>\n      <td>40.75985,-74.00306</td>\n      <td>40.75775,-74.00457</td>\n      <td>40.75775,-74.00457</td>\n      <td>40.75576,-74.00601</td>\n      <td>40.7544904,-74.006921</td>\n      <td>40.7538404,-74.007241</td>\n      <td>40.75415,-74.00712</td>\n      <td>40.7502804,-74.00848</td>\n      <td>40.74833,-74.007771</td>\n      <td>40.74114,-74.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4616338</td>\n      <td>9</td>\n      <td>40.7607,-74.002141</td>\n      <td>40.76212,-74.91</td>\n      <td>40.76335,-73.999271</td>\n      <td>40.76491,-73.99805</td>\n      <td>40.7667406,-73.996681</td>\n      <td>40.7693,-73.994801</td>\n      <td>40.7699605,-73.994521</td>\n      <td>40.7710104,-73.99438</td>\n      <td>40.7715106,-73.9942</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4616323</td>\n      <td>17</td>\n      <td>40.77158,-73.994441</td>\n      <td>40.7713004,-73.99455</td>\n      <td>40.77085,-73.99467</td>\n      <td>40.76997,-73.99481</td>\n      <td>40.7701604,-73.99477</td>\n      <td>40.76986,-73.994831</td>\n      <td>40.7695406,-73.99496</td>\n      <td>40.769341,-73.99508</td>\n      <td>40.768311,-73.9958</td>\n      <td>40.768311,-73.9958</td>\n      <td>40.76623,-73.99733</td>\n      <td>40.76623,-73.99733</td>\n      <td>40.76547,-73.9979</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "    linkId  EncodedPolyLineLvls               point0                point1  \\\n0  4616337                   13  40.74047,-74.009251    40.74137,-74.00893   \n1  4616325                    6   40.73933,-74.01004    40.73895,-74.01012   \n2  4616324                   15  40.76375,-73.999191   40.763521,-73.99935   \n3  4616338                    9   40.7607,-74.002141       40.76212,-74.91   \n4  4616323                   17  40.77158,-73.994441  40.7713004,-73.99455   \n\n                  point2                point3                 point4  \\\n0  40.7431706,-74.008591  40.7462304,-74.00797    40.74812,-74.007651   \n1     40.7376,-74.010021     40.7346,-74.01026    40.72912,-74.010781   \n2   40.7620804,-74.00136    40.75985,-74.00306     40.75775,-74.00457   \n3    40.76335,-73.999271    40.76491,-73.99805  40.7667406,-73.996681   \n4     40.77085,-73.99467    40.76997,-73.99481   40.7701604,-73.99477   \n\n                 point5                 point6                 point7  \\\n0  40.748701,-74.007691     40.74971,-74.00819    40.75048,-74.008321   \n1   40.72619,-74.011131                   None                   None   \n2    40.75775,-74.00457     40.75576,-74.00601  40.7544904,-74.006921   \n3    40.7693,-73.994801  40.7699605,-73.994521   40.7710104,-73.99438   \n4   40.76986,-73.994831   40.7695406,-73.99496    40.769341,-73.99508   \n\n                  point8                point9               point10  \\\n0    40.751611,-74.00789  40.7537504,-74.00704    40.75721,-74.00463   \n1                   None                  None                  None   \n2  40.7538404,-74.007241    40.75415,-74.00712  40.7502804,-74.00848   \n3    40.7715106,-73.9942                  None                  None   \n4     40.768311,-73.9958    40.768311,-73.9958    40.76623,-73.99733   \n\n               point11            point12  \n0  40.76003,-74.002631      40.7607405,-7  \n1                 None               None  \n2  40.74833,-74.007771     40.74114,-74.0  \n3                 None               None  \n4   40.76623,-73.99733  40.76547,-73.9979  "
                    },
                    "execution_count": 81,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_linkinfo.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Create the Traffic Dataset that contains the traffic speed data and store it in a Pandas DataFrame - df_traffic"
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Speed</th>\n      <th>TravelTime</th>\n      <th>Status</th>\n      <th>DataAsOf</th>\n      <th>linkId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>422</td>\n      <td>36.04</td>\n      <td>249</td>\n      <td>0</td>\n      <td>10/05/2016 09:41</td>\n      <td>4616298</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>423</td>\n      <td>11.81</td>\n      <td>434</td>\n      <td>0</td>\n      <td>10/05/2016 09:41</td>\n      <td>4616299</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>424</td>\n      <td>9.94</td>\n      <td>360</td>\n      <td>0</td>\n      <td>10/05/2016 09:41</td>\n      <td>4616300</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>425</td>\n      <td>47.85</td>\n      <td>225</td>\n      <td>0</td>\n      <td>10/05/2016 09:41</td>\n      <td>4616276</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>426</td>\n      <td>24.23</td>\n      <td>285</td>\n      <td>0</td>\n      <td>10/05/2016 09:41</td>\n      <td>4616272</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "    Id  Speed  TravelTime  Status          DataAsOf   linkId\n0  422  36.04         249       0  10/05/2016 09:41  4616298\n1  423  11.81         434       0  10/05/2016 09:41  4616299\n2  424   9.94         360       0  10/05/2016 09:41  4616300\n3  425  47.85         225       0  10/05/2016 09:41  4616276\n4  426  24.23         285       0  10/05/2016 09:41  4616272"
                    },
                    "execution_count": 61,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "body = client_74cc9913793c416c8e6e21855b2aa2d8.get_object(Bucket='datascienceprojectcoursera-donotdelete-pr-j5jbz0cymbpaj8',Key='october2016v2.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_traffic = pd.read_csv(body)\ndf_traffic.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [],
            "source": "df_traffic = pd.concat([df_traffic, df_traffic.DataAsOf.str.split(expand=True)], axis=1, sort=False)"
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [],
            "source": "df_traffic.rename(columns={0: 'Date', 1: 'Time'}, inplace=True)"
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [],
            "source": "# Take the leftmost 5 characters if there are more than 5 characters in the Time cell \n# (e.g. 10:10 as opposed to 10:10:78 since we dont care for the miliseconds)\ndf_traffic[\"Time\"] = df_traffic['Time'].apply(lambda x: x[:5] if len(x) > 5 else x)"
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [],
            "source": "df_traffic.drop(\"DataAsOf\", inplace=True, axis=1)"
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "Timestamp('2016-10-05 00:00:00')"
                    },
                    "execution_count": 69,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "pd.to_datetime(df_traffic['Date'][0])"
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {},
            "outputs": [],
            "source": "date = \"10/05/2016\""
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "'pat' is an invalid keyword argument for this function",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-97-fb9fcec01bf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmap_nyc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlatitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitude\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzoom_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_linkinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoint0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfolium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPolyLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopacity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmap_nyc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: 'pat' is an invalid keyword argument for this function"
                    ]
                }
            ],
            "source": "map_nyc = folium.Map(location=[latitude, longitude], zoom_start=19)\npoints = (,)\nfolium.PolyLine(points, color=\"red\", weight=2.5, opacity=1).add_to(my_map)\nmap_nyc"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}